{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train_set, y_train_set), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_set.shape, y_train_set.shape, x_test.shape, y_test. shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "print(y_train_set [i])\n",
    "plt.imshow(x_train_set[i], cmap='binary') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_set, \n",
    "                                                      y_train_set, \n",
    "                                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   1   0   0   0   0  63   0   0   0   0   0  22\n",
      "   10   0   0   0   3   0   0   0   0   0]\n",
      " [  0   0   0   1   0   1   0   0   0 113 226 247 216 185 147 146 207 235\n",
      "  210 136  15   0   0   2   0   0   0   0]\n",
      " [  0   0   0   0   2   0   0 138 221 234 222 218 243 255 255 255 255 223\n",
      "  218 235 223 172   0   0   4   0   0   0]\n",
      " [  0   0   0   2   0   0 205 239 215 212 214 206 213 216 220 220 216 213\n",
      "  218 214 212 239 213   0   0   0   0   0]\n",
      " [  0   0   0   0   0 163 236 208 215 216 217 215 215 215 209 212 215 215\n",
      "  215 219 218 206 234 100   0   0   0   0]\n",
      " [  0   0   0   0  47 234 215 215 215 215 214 214 215 214 215 216 216 215\n",
      "  215 215 217 215 223 232   0   0   0   0]\n",
      " [  0   0   0   0 189 231 222 214 214 215 215 215 215 215 214 215 216 216\n",
      "  216 218 217 218 219 238  78   0   0   0]\n",
      " [  0   0   0   0 217 216 229 225 215 216 214 215 215 214 214 215 215 216\n",
      "  217 218 217 221 225 230 194   0   0   0]\n",
      " [  0   0   0 130 235 209 225 233 211 214 216 216 217 216 214 215 215 216\n",
      "  218 219 212 226 221 221 208   0   0   0]\n",
      " [  0   0   0 159 208 231 246 254 222 212 224 218 217 219 219 219 218 218\n",
      "  221 217 219 253 242 237 240  61   0   0]\n",
      " [  0   0   0   0   0  49 150 226 244 207 225 219 217 218 219 219 218 219\n",
      "  223 212 241 229 165 119  67   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 220 225 218 216 217 218 218 218 217 218\n",
      "  224 203 255  42   0   0   0   0   0   0]\n",
      " [  0   0   0   0   2   3   0   0 206 222 213 218 214 218 217 217 219 216\n",
      "  222 209 255  69   0   5   5   2   0   0]\n",
      " [  0   0   0   0   0   0   0   0 207 222 214 217 215 217 217 217 218 218\n",
      "  223 209 227  55   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 214 220 217 215 219 215 217 217 219 217\n",
      "  221 210 219  35   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 218 220 217 213 221 214 217 217 219 215\n",
      "  219 212 215  22   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 218 224 214 213 219 216 219 219 220 218\n",
      "  218 212 217  30   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 210 227 212 215 219 217 218 218 220 216\n",
      "  214 213 218  30   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 214 228 210 218 218 217 218 219 218 222\n",
      "  224 209 217  34   0   6   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 226 225 207 219 218 218 218 219 218 218\n",
      "  233 209 221  42   0   6   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 229 222 206 219 219 219 217 218 220 216\n",
      "  232 215 222  49   0   7   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 225 220 210 220 219 219 218 219 221 218\n",
      "  221 220 222  49   0   7   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 228 217 212 222 219 219 219 220 221 220\n",
      "  215 219 225  28   0   6   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 236 215 216 220 219 220 220 219 222 222\n",
      "  219 215 227  85   0   7   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 194 216 217 218 219 220 219 218 221 221\n",
      "  223 215 227 129   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 190 214 215 212 213 213 212 212 214 217\n",
      "  216 213 217   0   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 211 230 228 252 252 252 250 250 252 255\n",
      "  253 225 238  56   0   6   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 110 109 121 126 133 132 130 130 130 129\n",
      "  129 129 160  18   0   4   0   0   0   0]]\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.00392157 0.         0.         0.         0.         0.24705882\n",
      "  0.         0.         0.         0.         0.         0.08627451\n",
      "  0.03921569 0.         0.         0.         0.01176471 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.00392157 0.         0.00392157\n",
      "  0.         0.         0.         0.44313725 0.88627451 0.96862745\n",
      "  0.84705882 0.7254902  0.57647059 0.57254902 0.81176471 0.92156863\n",
      "  0.82352941 0.53333333 0.05882353 0.         0.         0.00784314\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00784314 0.\n",
      "  0.         0.54117647 0.86666667 0.91764706 0.87058824 0.85490196\n",
      "  0.95294118 1.         1.         1.         1.         0.8745098\n",
      "  0.85490196 0.92156863 0.8745098  0.6745098  0.         0.\n",
      "  0.01568627 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.00784314 0.         0.\n",
      "  0.80392157 0.9372549  0.84313725 0.83137255 0.83921569 0.80784314\n",
      "  0.83529412 0.84705882 0.8627451  0.8627451  0.84705882 0.83529412\n",
      "  0.85490196 0.83921569 0.83137255 0.9372549  0.83529412 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.63921569\n",
      "  0.9254902  0.81568627 0.84313725 0.84705882 0.85098039 0.84313725\n",
      "  0.84313725 0.84313725 0.81960784 0.83137255 0.84313725 0.84313725\n",
      "  0.84313725 0.85882353 0.85490196 0.80784314 0.91764706 0.39215686\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.18431373 0.91764706\n",
      "  0.84313725 0.84313725 0.84313725 0.84313725 0.83921569 0.83921569\n",
      "  0.84313725 0.83921569 0.84313725 0.84705882 0.84705882 0.84313725\n",
      "  0.84313725 0.84313725 0.85098039 0.84313725 0.8745098  0.90980392\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.74117647 0.90588235\n",
      "  0.87058824 0.83921569 0.83921569 0.84313725 0.84313725 0.84313725\n",
      "  0.84313725 0.84313725 0.83921569 0.84313725 0.84705882 0.84705882\n",
      "  0.84705882 0.85490196 0.85098039 0.85490196 0.85882353 0.93333333\n",
      "  0.30588235 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.85098039 0.84705882\n",
      "  0.89803922 0.88235294 0.84313725 0.84705882 0.83921569 0.84313725\n",
      "  0.84313725 0.83921569 0.83921569 0.84313725 0.84313725 0.84705882\n",
      "  0.85098039 0.85490196 0.85098039 0.86666667 0.88235294 0.90196078\n",
      "  0.76078431 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.50980392 0.92156863 0.81960784\n",
      "  0.88235294 0.91372549 0.82745098 0.83921569 0.84705882 0.84705882\n",
      "  0.85098039 0.84705882 0.83921569 0.84313725 0.84313725 0.84705882\n",
      "  0.85490196 0.85882353 0.83137255 0.88627451 0.86666667 0.86666667\n",
      "  0.81568627 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.62352941 0.81568627 0.90588235\n",
      "  0.96470588 0.99607843 0.87058824 0.83137255 0.87843137 0.85490196\n",
      "  0.85098039 0.85882353 0.85882353 0.85882353 0.85490196 0.85490196\n",
      "  0.86666667 0.85098039 0.85882353 0.99215686 0.94901961 0.92941176\n",
      "  0.94117647 0.23921569 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.19215686\n",
      "  0.58823529 0.88627451 0.95686275 0.81176471 0.88235294 0.85882353\n",
      "  0.85098039 0.85490196 0.85882353 0.85882353 0.85490196 0.85882353\n",
      "  0.8745098  0.83137255 0.94509804 0.89803922 0.64705882 0.46666667\n",
      "  0.2627451  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.8627451  0.88235294 0.85490196 0.84705882\n",
      "  0.85098039 0.85490196 0.85490196 0.85490196 0.85098039 0.85490196\n",
      "  0.87843137 0.79607843 1.         0.16470588 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.00784314 0.01176471\n",
      "  0.         0.         0.80784314 0.87058824 0.83529412 0.85490196\n",
      "  0.83921569 0.85490196 0.85098039 0.85098039 0.85882353 0.84705882\n",
      "  0.87058824 0.81960784 1.         0.27058824 0.         0.01960784\n",
      "  0.01960784 0.00784314 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.81176471 0.87058824 0.83921569 0.85098039\n",
      "  0.84313725 0.85098039 0.85098039 0.85098039 0.85490196 0.85490196\n",
      "  0.8745098  0.81960784 0.89019608 0.21568627 0.         0.01176471\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.83921569 0.8627451  0.85098039 0.84313725\n",
      "  0.85882353 0.84313725 0.85098039 0.85098039 0.85882353 0.85098039\n",
      "  0.86666667 0.82352941 0.85882353 0.1372549  0.         0.01960784\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.85490196 0.8627451  0.85098039 0.83529412\n",
      "  0.86666667 0.83921569 0.85098039 0.85098039 0.85882353 0.84313725\n",
      "  0.85882353 0.83137255 0.84313725 0.08627451 0.         0.01568627\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.85490196 0.87843137 0.83921569 0.83529412\n",
      "  0.85882353 0.84705882 0.85882353 0.85882353 0.8627451  0.85490196\n",
      "  0.85490196 0.83137255 0.85098039 0.11764706 0.         0.01568627\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.82352941 0.89019608 0.83137255 0.84313725\n",
      "  0.85882353 0.85098039 0.85490196 0.85490196 0.8627451  0.84705882\n",
      "  0.83921569 0.83529412 0.85490196 0.11764706 0.         0.01960784\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.83921569 0.89411765 0.82352941 0.85490196\n",
      "  0.85490196 0.85098039 0.85490196 0.85882353 0.85490196 0.87058824\n",
      "  0.87843137 0.81960784 0.85098039 0.13333333 0.         0.02352941\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.88627451 0.88235294 0.81176471 0.85882353\n",
      "  0.85490196 0.85490196 0.85490196 0.85882353 0.85490196 0.85490196\n",
      "  0.91372549 0.81960784 0.86666667 0.16470588 0.         0.02352941\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.89803922 0.87058824 0.80784314 0.85882353\n",
      "  0.85882353 0.85882353 0.85098039 0.85490196 0.8627451  0.84705882\n",
      "  0.90980392 0.84313725 0.87058824 0.19215686 0.         0.02745098\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.88235294 0.8627451  0.82352941 0.8627451\n",
      "  0.85882353 0.85882353 0.85490196 0.85882353 0.86666667 0.85490196\n",
      "  0.86666667 0.8627451  0.87058824 0.19215686 0.         0.02745098\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.89411765 0.85098039 0.83137255 0.87058824\n",
      "  0.85882353 0.85882353 0.85882353 0.8627451  0.86666667 0.8627451\n",
      "  0.84313725 0.85882353 0.88235294 0.10980392 0.         0.02352941\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.9254902  0.84313725 0.84705882 0.8627451\n",
      "  0.85882353 0.8627451  0.8627451  0.85882353 0.87058824 0.87058824\n",
      "  0.85882353 0.84313725 0.89019608 0.33333333 0.         0.02745098\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.76078431 0.84705882 0.85098039 0.85490196\n",
      "  0.85882353 0.8627451  0.85882353 0.85490196 0.86666667 0.86666667\n",
      "  0.8745098  0.84313725 0.89019608 0.50588235 0.         0.01960784\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.74509804 0.83921569 0.84313725 0.83137255\n",
      "  0.83529412 0.83529412 0.83137255 0.83137255 0.83921569 0.85098039\n",
      "  0.84705882 0.83529412 0.85098039 0.         0.         0.01960784\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00784314\n",
      "  0.         0.         0.82745098 0.90196078 0.89411765 0.98823529\n",
      "  0.98823529 0.98823529 0.98039216 0.98039216 0.98823529 1.\n",
      "  0.99215686 0.88235294 0.93333333 0.21960784 0.         0.02352941\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.00392157\n",
      "  0.         0.         0.43137255 0.42745098 0.4745098  0.49411765\n",
      "  0.52156863 0.51764706 0.50980392 0.50980392 0.50980392 0.50588235\n",
      "  0.50588235 0.50588235 0.62745098 0.07058824 0.         0.01568627\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "x_train2 = x_train / 255.0\n",
    "print(x_train2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 28, 28) (15000, 28, 28) (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "x_train = x_train / 255.0\n",
    "x_valid =x_valid / 255.0\n",
    "x_test = x_test / 255.0\n",
    "print(x_train.shape, x_valid.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np. random. seed (1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    #第一層：將 28*28攤平成一維度\n",
    "    Flatten(input_shape=x_train.shape[1:]),\n",
    "    #第二層\n",
    "    Dense (units=300, activation='relu'),\n",
    "    Dense (units=200, activation='relu'),\n",
    "    Dense (units=100, activation='relu'),\n",
    "    #輸出層：10類別，10個神經元\n",
    "    Dense (units=10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               60200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               20100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 316810 (1.21 MB)\n",
      "Trainable params: 316810 (1.21 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下3種opt寫法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile01\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "               optimizer='sgd', \n",
    "               metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile02\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "               optimizer=opt, \n",
    "               metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile03\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "               optimizer=tf.keras.optimizers.SGD(learning_rate=0.01), \n",
    "               metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.7837 - accuracy: 0.7393 - val_loss: 0.6349 - val_accuracy: 0.7751\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 3s 2ms/step - loss: 0.4972 - accuracy: 0.8256 - val_loss: 0.5102 - val_accuracy: 0.8166\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4461 - accuracy: 0.8420 - val_loss: 0.4568 - val_accuracy: 0.8355\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.4153 - accuracy: 0.8522 - val_loss: 0.4162 - val_accuracy: 0.8503\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3939 - accuracy: 0.8604 - val_loss: 0.9604 - val_accuracy: 0.6727\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3767 - accuracy: 0.8672 - val_loss: 0.5820 - val_accuracy: 0.8066\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3603 - accuracy: 0.8710 - val_loss: 0.3873 - val_accuracy: 0.8582\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3489 - accuracy: 0.8754 - val_loss: 0.3921 - val_accuracy: 0.8556\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3363 - accuracy: 0.8787 - val_loss: 0.4104 - val_accuracy: 0.8531\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3268 - accuracy: 0.8816 - val_loss: 0.4779 - val_accuracy: 0.8380\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3174 - accuracy: 0.8857 - val_loss: 0.3535 - val_accuracy: 0.8727\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3086 - accuracy: 0.8883 - val_loss: 0.5006 - val_accuracy: 0.8183\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.3007 - accuracy: 0.8906 - val_loss: 0.3839 - val_accuracy: 0.8594\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2922 - accuracy: 0.8948 - val_loss: 0.3454 - val_accuracy: 0.8744\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2853 - accuracy: 0.8960 - val_loss: 0.3489 - val_accuracy: 0.8737\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2789 - accuracy: 0.8981 - val_loss: 0.3376 - val_accuracy: 0.8774\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2723 - accuracy: 0.9018 - val_loss: 0.3659 - val_accuracy: 0.8686\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2662 - accuracy: 0.9037 - val_loss: 0.3375 - val_accuracy: 0.8793\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2603 - accuracy: 0.9055 - val_loss: 0.3457 - val_accuracy: 0.8748\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 4s 3ms/step - loss: 0.2535 - accuracy: 0.9062 - val_loss: 0.3206 - val_accuracy: 0.8859\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "train = model.fit(x_train, y_train,\n",
    "                   epochs=20, \n",
    "                  validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
